# -*- coding: utf-8 -*-
"""TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K9pL018y8ys7mMXjwTGOfc8A_lhKBPat

#NIH CXR8 **Classification** Tutorial
**_Estimated completion time: 30 minutes_**

We will break down the process into five steps:

1. **Defining a problem**: what do we want our model to look for? For this we'll need to think of pathology we might find in a chest x-ray.
2. **Data preparation**: we'll talk about how to manipulate our data in a way the classification model can understand.
3. **Training a model**: we'll use a technology called [TensorFlow](
https://wwww.tensorflow.org) to create our model.
4. **Evaluating model performace**: we'll talk about some important considerations when creating a model like this.
5. **Deployment**: we'll send our model to a website where we can then test it in the wild and send to others.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import sklearn.metrics
import random
import tensorflow as tf
import matplotlib.pyplot as plt
import os
import io
import glob
import scipy.misc
import numpy as np
import pandas as pd
from six import BytesIO
from PIL import Image, ImageDraw, ImageFont
import shutil
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras import layers
from tensorflow.keras import Model
import matplotlib
from tensorflow.keras.optimizers import RMSprop
import os
import zipfile
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.image as mpimg

LEARNING_RATE = 0.0001
repo_url = 'https://github.com/adleberg/medical-ai'
IMAGE_HEIGHT, IMAGE_WIDTH = 256, 256

def load_image_into_numpy_array(image):
    image = image.convert('RGB')
    (im_width, im_height) = image.size
    return np.array(image.getdata()).reshape(
        (im_height, im_width, 3)).astype(np.uint8)

print("Welcome! Downloading some things... this will take a minute.")

# %cd -q /content
repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))
!git clone {repo_url} --quiet
# %cd -q {repo_dir_path}
!git pull -q

print("Great! You clicked on it correctly. Now let's get started.")

"""##1. Defining a Problem
Great! Let's start by thinking of something we can look for in a chest xray.

Once we think of something, let's type it in below, in between the quotes `""`, and run the cell. I'll put in `"atelectasis"` by default, but let's see if we can think of something else.

We'll be using a subset of the [NIH CXR8 dataset](https://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf) for this project, but this principles here apply to any project. The NIH CXR8 dataset only has a few selected findings within its dataset, but let's pretend that we're creating a dataset from scratch (using Montage, e.g.). Of note, this dataset also has bounding boxes available to us for another demonstration on object detection.

We'll need to see how many examples there are of the finding we typed in. Let's run the cell below to see.

![Screen Shot 2020-11-08 at 1.14.35 PM.png](data:image/png;base64,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)

Above are the labels we have available to us in this dataset.
"""

finding = "cardiomegaly"
finding = finding.capitalize()

df = pd.read_csv("/content/medical-ai/labels.csv")
df.head()

positives = df.loc[df["label"] == finding]
negatives = df.loc[df["label"] == "No finding"]
n = len(positives)

if n == 0:
  print("No studies found! Maybe check your spelling?")
  assert (n > 0)
else:
  print(n)

TRAIN_RATIO = 0.8
TEST_RATIO = 0.2
n = len(positives)
TRAIN_N = int(n*TRAIN_RATIO)
TEST_N = int(n*TEST_RATIO)
print(TRAIN_N, TEST_N)

train_labels = pd.concat([positives[:TRAIN_N], negatives[:TRAIN_N]])
test_labels = pd.concat([positives[TRAIN_N:], negatives[TRAIN_N:n]])

"""##2. Preparing the Data

Now, we've figured out what we want our model to take a look at. Behind the scenes, we just need to sort the data into two folders: one with **negative** cases and one with **positive** cases.
"""

rootdir = "/content/medical-ai/images/"
os.makedirs(rootdir+finding+"/test/positive",  exist_ok=True)
os.makedirs(rootdir+finding+"/test/negative",  exist_ok=True)
os.makedirs(rootdir+finding+"/train/positive", exist_ok=True)
os.makedirs(rootdir+finding+"/train/negative", exist_ok=True)

# copy images to new directories for training purposes
for idx, image in positives[:TRAIN_N].iterrows():
  source = rootdir+image["filename"]
  dst = rootdir+finding+"/train/positive/"+image["filename"]
  shutil.copy(source, dst)

for idx, image in positives[TRAIN_N:].iterrows():
  source = rootdir+image["filename"]
  dst = rootdir+finding+"/test/positive/"+image["filename"]
  shutil.copy(source, dst)

for idx, image in negatives[:TRAIN_N].iterrows():
  source = rootdir+image["filename"]
  dst = rootdir+finding+"/train/negative/"+image["filename"]
  shutil.copy(source, dst)

for idx, image in negatives[TRAIN_N:n].iterrows():
  source = rootdir+image["filename"]
  dst = rootdir+finding+"/test/negative/"+image["filename"]
  shutil.copy(source, dst)

print("Done moving "+str(n*2)+" images to positive and negative folders.")

# load images into memory for visualization
positive_imgs, negative_imgs = [], []
IMAGE_HEIGHT, IMAGE_WIDTH = 256, 256

for idx, row in positives[:6].iterrows():
  image_path = rootdir+row["filename"]
  image = Image.open(image_path).resize((IMAGE_WIDTH, IMAGE_HEIGHT))
  positive_imgs.append(load_image_into_numpy_array(image))

for idx, row in negatives[:6].iterrows():
  image_path = rootdir+row["filename"]
  image = Image.open(image_path).resize((IMAGE_WIDTH, IMAGE_HEIGHT))
  negative_imgs.append(load_image_into_numpy_array(image))

for idx, img in enumerate(positive_imgs[:6]):
  plt.subplot(2, 3, idx+1)
  plt.title(finding)
  plt.imshow(positive_imgs[idx])
plt.show()

for idx, img in enumerate(negative_imgs[:6]):
  plt.subplot(2, 3, idx+1)
  plt.title("No Findings")
  plt.imshow(negative_imgs[idx])
plt.show()

"""##3. Training the Model

Now, we will train the model. This is the cool part.

We will be using a technology called [Inception V3](https://arxiv.org/abs/1512.00567) to look at our images. This is a model that Google created to do image analysis, and has released to the general public. It's pretty smart -- let's see how smart it is on our images.

One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This particular model was trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes).
"""

pre_trained_model = InceptionV3(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), weights='imagenet', include_top=False)

for layer in pre_trained_model.layers:
  layer.trainable = False

last_layer = pre_trained_model.get_layer('mixed7')
last_output = last_layer.output

x = layers.Flatten()(last_output) # Flatten the output layer to 1 dimension
x = layers.Dense(1024, activation='relu')(x) # Add a fully connected layer with 1,024 hidden units and ReLU activation
x = layers.Dropout(0.2)(x) # Add a dropout rate of 0.2
x = layers.Dense(1, activation='sigmoid')(x) # Add a final sigmoid layer for classification

model = Model(pre_trained_model.input, x) # Configure and compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])
print("Done compiling the model!")

# Define our example directories and files
base_dir = rootdir = "/content/medical-ai/images/"
train_dir = os.path.join(base_dir, finding, 'train')
test_dir = os.path.join(base_dir, finding, 'test')

train_pos_dir = os.path.join(train_dir, 'positive')
train_neg_dir = os.path.join(train_dir, 'negative')
test_pos_dir = os.path.join(test_dir, 'positive')
test_neg_dir = os.path.join(test_dir, 'negative')

# Add our data-augmentation parameters to ImageDataGenerator
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=False
)

# Note that the test data should not be augmented!
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir, # This is the source directory for training images
        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
        batch_size=1,
        class_mode='binary'
)

test_generator = val_datagen.flow_from_directory(
        test_dir,
        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
        batch_size=1,
        class_mode='binary'
)

train_steps = len(os.listdir(train_pos_dir)) * 2
test_steps = len(os.listdir(test_pos_dir)) * 2
print("Done funneling data!")

"""##4. Running the Model
Finally, let's train the model using the features we extracted.
We'll train on all 80% of the labels we have, and verify their accuracy on the remaining 20%.
"""

history = model.fit(
      train_generator,
      steps_per_epoch=train_steps,
      epochs=20,
      validation_data=test_generator,
      validation_steps=test_steps,
      verbose=2
)

"""Let's plot the training and test loss and accuracy to show it conclusively:"""

# Retrieve a list of accuracy results on training and test data sets for each training epoch
acc = history.history['acc']
val_acc = history.history['val_acc']

# Retrieve a list of list results on training and test data sets for each training epoch
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

plt.subplot(2,1,1)
plt.plot(epochs, acc, label="train")
plt.plot(epochs, val_acc, label="test")
plt.ylabel("Accuracy")
plt.title('Training and test accuracy')
plt.legend(loc="lower right")

plt.subplot(2,1,2)
plt.plot(epochs, loss, label="train")
plt.plot(epochs, val_loss, label="test")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title('Training and test loss')
plt.legend(loc="lower right")

plt.show()

"""##5. Evaluating Performance

In this section we will investigate how it works on different parts.
"""

def predict_image(filename):
  image = Image.open(filename).resize((IMAGE_HEIGHT, IMAGE_WIDTH))
  image_np = load_image_into_numpy_array(image)
  exp = np.true_divide(image_np, 255.0)
  expanded = np.expand_dims(exp, axis=0)
  return model.predict(expanded)[0][0]

def show_df_row(row):
  image_path = row["filepath"]
  image = Image.open(image_path).resize((IMAGE_WIDTH, IMAGE_HEIGHT))
  img = load_image_into_numpy_array(image)
  exp = np.true_divide(img, 255.0)
  expanded = np.expand_dims(exp, axis=0)
  pred = model.predict(expanded)[0][0]
  guess = "neg"
  if pred > 0.5:
    guess = "pos"
  title = "Image: "+row["filename"] + " Label: " + row["label"] + " Guess: " + guess + " Score: " + str(pred)
  plt.title(title)
  plt.imshow(img)
  plt.show()
  return

results = []
for image in os.listdir(test_neg_dir):
  filename = test_neg_dir + "/" + image
  confidence = predict_image(filename)
  guess = 'pos' if confidence > 0.5 else 'neg'
  results.append([filename, image, "neg", guess, confidence])

for image in os.listdir(test_pos_dir):
  filename = test_pos_dir + "/" + image
  confidence = predict_image(filename)
  guess = 'pos' if confidence > 0.5 else 'neg'
  results.append([filename, image, "pos", guess, confidence])

sorted_results = sorted(results, key=lambda x: x[4], reverse=True)
df = pd.DataFrame(data=sorted_results, columns=["filepath", "filename", "label", "guess", "confidence"])

print("Done inference!")

df.head()

"""###5a. Example image"""

n = random.randint(0, len(df)-1)
show_df_row(df.iloc[n])

"""###5b. Show Table of images"""

df[::5][['filename', 'label', "guess", "confidence"]]

"""###5c. Show histogram"""

from matplotlib.ticker import FormatStrFormatter
pos = df.loc[df['label'] == "pos"]["confidence"]
neg = df.loc[df['label'] == "neg"]["confidence"]
fig, ax = plt.subplots()
n, bins, patches = plt.hist([pos,neg], np.arange(0.0, 1.1, 0.1).tolist(), edgecolor='black', linewidth=0.5, density=False, histtype='bar', stacked=True, color=['green', 'red'], label=[finding, 'Negative'])
plt.xlabel('Confidence')
plt.ylabel('N')
plt.xticks(bins)
ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))
plt.title('Confidence scores for different values')
plt.legend(loc="lower right", fontsize=16)
plt.show()

"""###5d. Create cutoff point"""

cutoff = 0.59 #@param {type:"slider", min:0, max:1, step:0.01}

def create_with_cutoff(cutoff):
  __, ax = plt.subplots()
  TP = df.loc[(df['label'] == "pos") & (df["confidence"] > cutoff)]["confidence"]
  FP = df.loc[(df['label'] == "neg") & (df["confidence"] > cutoff)]["confidence"]
  FN = df.loc[(df['label'] == "pos") & (df["confidence"] < cutoff)]["confidence"]
  TN = df.loc[(df['label'] == "neg") & (df["confidence"] < cutoff)]["confidence"]

  plt.hist([TP,FP,TN,FN], np.arange(0.0, 1.1, 0.1).tolist(), \
           edgecolor='black', linewidth=0.5, density=False, histtype='bar', \
           stacked=True, color=['limegreen','forestgreen','orangered','salmon'], \
           label=['TP','FP','TN','FN'])
  plt.xlabel('Confidence')
  plt.ylabel('N')
  plt.xticks(bins)
  ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))
  plt.title('Confidence scores for different values')
  plt.axvline(cutoff, color='k', linestyle='dashed', linewidth=2)
  plt.legend(loc="lower right", fontsize=16)

  sens = round(len(TP) / (len(TP)+len(FN)),2)
  spec = round(len(TN) / (len(TN)+len(FP)),2)
  stats = "sensitivity: " + str(sens) + "\n" + "specificity: " + str(spec) + "\n\n" + "TP: "+str(len(TP)) + "\n" + "FP: " + str(len(FP)) + "\n"+"TN: " + str(len(TN)) + "\n" + "FN: " + str(len(FN))
  plt.text(0.05, 0.05, stats, fontsize=14, transform=ax.transAxes)
  plt.show()

create_with_cutoff(cutoff)

"""###5e. Show ROC Curve"""

def create_auc_curve(classifications):
  squares = {}
  for x in classifications:
    conf = x[4]
    TP, FP, TN, FN = 0, 0, 0, 0
    for row in classifications:
      assert (row[2] == "neg" or row[2] == "pos")
      if row[2] == "neg":
        if float(row[4]) < conf: TN += 1
        else: FP += 1
      else:
        if float(row[4]) > conf: TP += 1
        else: FN += 1
    squares[conf] = [TP, FP, TN, FN]
  # now we have a list of stuff: convert to
  sens_spec = {}
  for entry in squares:
    sens = squares[entry][0] / float(squares[entry][0] + squares[entry][3])
    spec = squares[entry][2] / float(squares[entry][2] + squares[entry][1])
    sens_spec[entry] = (1-spec, sens)
  return squares, sens_spec

squares, sens_spec = create_auc_curve(sorted_results)

x = []
y = []
for point in sens_spec.keys():
  x.append(sens_spec[point][0])
  y.append(sens_spec[point][1])

auc = sklearn.metrics.auc(x, y)

plt.figure()
lw = 2
plt.plot(x, y, color='darkorange', lw=lw, label='ROC curve (area = %0.3f)' % auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.ylabel('Sensitivity')
plt.xlabel('1-specificity')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right", fontsize=20)
plt.show()

"""###5f. Save Model"""

model.save('/content/export/'+finding)
!zip -r /content/{finding}.zip /content/export/{finding}

"""## Clean Up

Run the following cell to terminate the kernel and free memory resources:
"""

import os, signal
os.kill(os.getpid(), signal.SIGKILL)